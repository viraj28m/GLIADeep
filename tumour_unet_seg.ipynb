{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DECATHLON_ROOT_DIRECTORY']=os.getcwd()+'Brats/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvf Brats/data/Task01_BrainTumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/external_drive/MRI_Deep_Learning/unet/2D\n",
      "\u001b[H\u001b[2JScript to train Decathlon Brain Tumor Segmentation (BraTS) U-Net model\n",
      "======================================================================\n",
      "You need to download the dataset from http://medicaldecathlon.com\n",
      "Download the tar file 'Task01_BrainTumour.tar'\n",
      "Then extract the data from the tar file\n",
      "tar -xvf Task01_BrainTumour.tar\n",
      "Make sure to change the DECATHLON_DIR variable in this script\n",
      " to wherever you untarred the dataset.\n",
      " \n",
      "******************************************\n",
      "Step 1 of 4: Convert raw data to HDF5 file\n",
      "******************************************\n",
      "Converting Decathlon raw data to HDF5 file.\n",
      "Converting Decathlon raw Nifti data files to single training and validation HDF5 data file.\n",
      "Namespace(data_path='/external_drive/MRI_Deep_Learning/tumour_seg/Task01_BrainTumour', output_filename='Task01_BrainTumour.h5', resize=240, save_path='/external_drive/MRI_Deep_Learning/tumour_seg', split=0.85)\n",
      "Removing existing data file: /external_drive/MRI_Deep_Learning/tumour_seg/Task01_BrainTumour.h5\n",
      "******************************\n",
      "==============================\n",
      "Dataset name:         BRATS\n",
      "Dataset description:  Gliomas segmentation tumour and oedema in on brain images\n",
      "Tensor image size:    4D\n",
      "Dataset release:      2.0 04/05/2018\n",
      "Dataset reference:    https://www.med.upenn.edu/sbia/brats2017.html\n",
      "Dataset license:      CC-BY-SA 4.0\n",
      "==============================\n",
      "******************************\n",
      "Data shapes\n",
      "===========\n",
      "n.b. All tensors converted to stacks of 2D slices.\n",
      "If you want true 3D tensors, then modify this code appropriately.\n",
      "Raw Image shape     =  (240, 240, 155, 4)\n",
      "Cropped Image shape = (?, 240, 240, 1)\n",
      "Raw Masks shape     =  (240, 240, 155)\n",
      "Cropped Masks shape = (?, 240, 240, 1)\n",
      "Step 1 of 6. Save training set images.\n",
      "100%|█████████████████████████████████████████| 406/406 [11:44<00:00,  1.74s/it]\n",
      "Step 2 of 6. Save validation set images.\n",
      "100%|███████████████████████████████████████████| 32/32 [00:55<00:00,  1.73s/it]\n",
      "Step 3 of 6. Save testing set images.\n",
      "100%|███████████████████████████████████████████| 46/46 [01:19<00:00,  1.73s/it]\n",
      "Step 4 of 6. Save training set masks.\n",
      "100%|█████████████████████████████████████████| 406/406 [03:16<00:00,  2.06it/s]\n",
      "Step 5 of 6. Save validation set masks.\n",
      "100%|███████████████████████████████████████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "Step 6 of 6. Save testing set masks.\n",
      "100%|███████████████████████████████████████████| 46/46 [00:22<00:00,  2.07it/s]\n",
      "Finished processing.\n",
      "HDF5 saved to /external_drive/MRI_Deep_Learning/tumour_seg/Task01_BrainTumour.h5\n",
      " \n",
      "***********************************\n",
      "Step 2 of 4: Train U-Net on dataset\n",
      "***********************************\n",
      "Run U-Net training on BraTS Decathlon dataset\n",
      "Using TensorFlow backend.\n",
      "TensorFlow version: 1.11.0\n",
      "Intel MKL-DNN is enabled = False\n",
      "Keras API version: 2.2.4\n",
      "Started script on 2020-01-21 21:33:52.050961\n",
      "args = Namespace(batch_size=128, blocktime=1000, channels_first=False, cpu_extension=None, crop_dim=144, data_filename='Task01_BrainTumour.h5', data_path='/external_drive/MRI_Deep_Learning/tumour_seg', device='CPU', epochs=20, featuremaps=32, hdf5_datafile='../../data/decathlon/144x144/Task01_BrainTumour.h5', inference_filename='unet_model_for_decathlon.hdf5', input_filename='output/unet_model_for_decathlon.hdf5', keras_api=True, learningrate=0.0001, num_inter_threads=1, num_threads=2, number_iter=5, output_directory='output/saved_2dunet_model_protobuf', output_frozen_model_dir='output/frozen_model', output_path='./output', output_pngs='inference_examples', plot=True, plugin_dir=None, print_model=True, rows_per_image=4, seed=816, stats=False, use_augmentation=True, use_dropout=False, use_pconv=False, use_upsampling=False, weight_dice_loss=0.9)\n",
      "TensorFlow version: 1.11.0\n",
      "------------------------------\n",
      "Loading the data from HDF5 file ...\n",
      "------------------------------\n",
      "hdf5_filename\n",
      "/external_drive/MRI_Deep_Learning/tumour_seg/Task01_BrainTumour.h5\n",
      "Batch size = 128\n",
      "Training image dimensions:   (62930, 144, 144, 1)\n",
      "Training mask dimensions:    (62930, 144, 144, 1)\n",
      "Validation image dimensions: (4960, 144, 144, 1)\n",
      "Validation mask dimensions:  (4960, 144, 144, 1)\n",
      "Testing image dimensions: (7130, 144, 144, 1)\n",
      "Testing mask dimensions:  (7130, 144, 144, 1)\n",
      "------------------------------\n",
      "Creating and compiling model ...\n",
      "------------------------------\n",
      "Data format = channels_last\n",
      "Using Transposed Deconvolution\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "MRImages (InputLayer)           (None, None, None, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encodeAa (Conv2D)               (None, None, None, 3 320         MRImages[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeAb (Conv2D)               (None, None, None, 3 9248        encodeAa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolA (MaxPooling2D)            (None, None, None, 3 0           encodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeBa (Conv2D)               (None, None, None, 6 18496       poolA[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeBb (Conv2D)               (None, None, None, 6 36928       encodeBa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolB (MaxPooling2D)            (None, None, None, 6 0           encodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeCa (Conv2D)               (None, None, None, 1 73856       poolB[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeCb (Conv2D)               (None, None, None, 1 147584      encodeCa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolC (MaxPooling2D)            (None, None, None, 1 0           encodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeDa (Conv2D)               (None, None, None, 2 295168      poolC[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeDb (Conv2D)               (None, None, None, 2 590080      encodeDa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolD (MaxPooling2D)            (None, None, None, 2 0           encodeDb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeEa (Conv2D)               (None, None, None, 5 1180160     poolD[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeEb (Conv2D)               (None, None, None, 5 2359808     encodeEa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transconvE (Conv2DTranspose)    (None, None, None, 2 524544      encodeEb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatD (Concatenate)           (None, None, None, 5 0           transconvE[0][0]                 \n",
      "                                                                 encodeDb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeCa (Conv2D)               (None, None, None, 2 1179904     concatD[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeCb (Conv2D)               (None, None, None, 2 590080      decodeCa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transconvC (Conv2DTranspose)    (None, None, None, 1 131200      decodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatC (Concatenate)           (None, None, None, 2 0           transconvC[0][0]                 \n",
      "                                                                 encodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeBa (Conv2D)               (None, None, None, 1 295040      concatC[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeBb (Conv2D)               (None, None, None, 1 147584      decodeBa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transconvB (Conv2DTranspose)    (None, None, None, 6 32832       decodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatB (Concatenate)           (None, None, None, 1 0           transconvB[0][0]                 \n",
      "                                                                 encodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeAa (Conv2D)               (None, None, None, 6 73792       concatB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeAb (Conv2D)               (None, None, None, 6 36928       decodeAa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transconvA (Conv2DTranspose)    (None, None, None, 3 8224        decodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatA (Concatenate)           (None, None, None, 6 0           transconvA[0][0]                 \n",
      "                                                                 encodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convOuta (Conv2D)               (None, None, None, 3 18464       concatA[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convOutb (Conv2D)               (None, None, None, 3 9248        convOuta[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "PredictionMask (Conv2D)         (None, None, None, 1 33          convOutb[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Writing model to './output/unet_model_for_decathlon.hdf5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fitting model with training data ...\n",
      "------------------------------\n",
      "Train on 62930 samples, validate on 4960 samples\n",
      "Epoch 1/20\n",
      "62930/62930 [==============================] - 1002s 16ms/step - loss: 2.1156 - acc: 0.7822 - dice_coef: 0.2918 - soft_dice_coef: 0.1841 - val_loss: 1.9399 - val_acc: 0.8484 - val_dice_coef: 0.4332 - val_soft_dice_coef: 0.3978\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.93994, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 2/20\n",
      "62930/62930 [==============================] - 987s 16ms/step - loss: 1.9002 - acc: 0.8608 - dice_coef: 0.4105 - soft_dice_coef: 0.3749 - val_loss: 1.8380 - val_acc: 0.8672 - val_dice_coef: 0.4245 - val_soft_dice_coef: 0.4067\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.93994 to 1.83801, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 3/20\n",
      "62930/62930 [==============================] - 979s 16ms/step - loss: 1.7209 - acc: 0.8998 - dice_coef: 0.4576 - soft_dice_coef: 0.4466 - val_loss: 1.7925 - val_acc: 0.9059 - val_dice_coef: 0.5255 - val_soft_dice_coef: 0.5222\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.83801 to 1.79254, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 4/20\n",
      "62930/62930 [==============================] - 982s 16ms/step - loss: 1.5775 - acc: 0.9203 - dice_coef: 0.5015 - soft_dice_coef: 0.4813 - val_loss: 1.6591 - val_acc: 0.8975 - val_dice_coef: 0.4776 - val_soft_dice_coef: 0.3968\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.79254 to 1.65914, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 5/20\n",
      "62930/62930 [==============================] - 981s 16ms/step - loss: 1.5834 - acc: 0.9107 - dice_coef: 0.4813 - soft_dice_coef: 0.4015 - val_loss: 1.6900 - val_acc: 0.9160 - val_dice_coef: 0.4389 - val_soft_dice_coef: 0.4377\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.65914\n",
      "Epoch 6/20\n",
      "62930/62930 [==============================] - 984s 16ms/step - loss: 1.3902 - acc: 0.9354 - dice_coef: 0.5377 - soft_dice_coef: 0.5109 - val_loss: 1.3272 - val_acc: 0.9349 - val_dice_coef: 0.5678 - val_soft_dice_coef: 0.5559\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.65914 to 1.32720, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 7/20\n",
      "62930/62930 [==============================] - 985s 16ms/step - loss: 1.2013 - acc: 0.9474 - dice_coef: 0.5722 - soft_dice_coef: 0.4739 - val_loss: 1.2465 - val_acc: 0.9610 - val_dice_coef: 0.6085 - val_soft_dice_coef: 0.6037\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.32720 to 1.24650, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 8/20\n",
      "62930/62930 [==============================] - 989s 16ms/step - loss: 1.1254 - acc: 0.9534 - dice_coef: 0.6040 - soft_dice_coef: 0.4665 - val_loss: 1.1781 - val_acc: 0.9480 - val_dice_coef: 0.6064 - val_soft_dice_coef: 0.5936\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.24650 to 1.17805, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 9/20\n",
      "62930/62930 [==============================] - 992s 16ms/step - loss: 0.9808 - acc: 0.9634 - dice_coef: 0.6361 - soft_dice_coef: 0.4952 - val_loss: 0.9672 - val_acc: 0.9591 - val_dice_coef: 0.6364 - val_soft_dice_coef: 0.4091\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.17805 to 0.96717, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 10/20\n",
      "62930/62930 [==============================] - 989s 16ms/step - loss: 0.9478 - acc: 0.9661 - dice_coef: 0.6383 - soft_dice_coef: 0.3875 - val_loss: 0.8737 - val_acc: 0.9697 - val_dice_coef: 0.6795 - val_soft_dice_coef: 0.5322\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.96717 to 0.87366, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 11/20\n",
      "62930/62930 [==============================] - 991s 16ms/step - loss: 0.8304 - acc: 0.9709 - dice_coef: 0.6684 - soft_dice_coef: 0.4567 - val_loss: 0.8896 - val_acc: 0.9725 - val_dice_coef: 0.6839 - val_soft_dice_coef: 0.3727\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.87366\n",
      "Epoch 12/20\n",
      "62930/62930 [==============================] - 992s 16ms/step - loss: 0.7657 - acc: 0.9730 - dice_coef: 0.6837 - soft_dice_coef: 0.5100 - val_loss: 1.4548 - val_acc: 0.9710 - val_dice_coef: 0.6502 - val_soft_dice_coef: 0.4158\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.87366\n",
      "Epoch 13/20\n",
      "62930/62930 [==============================] - 992s 16ms/step - loss: 0.7397 - acc: 0.9733 - dice_coef: 0.6890 - soft_dice_coef: 0.5519 - val_loss: 0.9543 - val_acc: 0.9751 - val_dice_coef: 0.6922 - val_soft_dice_coef: 0.5712\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.87366\n",
      "Epoch 14/20\n",
      "62930/62930 [==============================] - 990s 16ms/step - loss: 0.6321 - acc: 0.9764 - dice_coef: 0.7041 - soft_dice_coef: 0.5000 - val_loss: 0.8843 - val_acc: 0.9708 - val_dice_coef: 0.6708 - val_soft_dice_coef: 0.5592\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.87366\n",
      "Epoch 15/20\n",
      "62930/62930 [==============================] - 994s 16ms/step - loss: 0.6772 - acc: 0.9745 - dice_coef: 0.6950 - soft_dice_coef: 0.5841 - val_loss: 0.6973 - val_acc: 0.9740 - val_dice_coef: 0.7028 - val_soft_dice_coef: 0.6415\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.87366 to 0.69728, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "Epoch 16/20\n",
      "62930/62930 [==============================] - 989s 16ms/step - loss: 0.5968 - acc: 0.9770 - dice_coef: 0.7136 - soft_dice_coef: 0.6196 - val_loss: 0.7000 - val_acc: 0.9754 - val_dice_coef: 0.7102 - val_soft_dice_coef: 0.5663\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.69728\n",
      "Epoch 17/20\n",
      "62930/62930 [==============================] - 988s 16ms/step - loss: 0.5643 - acc: 0.9784 - dice_coef: 0.7213 - soft_dice_coef: 0.6877 - val_loss: 0.7522 - val_acc: 0.9735 - val_dice_coef: 0.7033 - val_soft_dice_coef: 0.6705\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.69728\n",
      "Epoch 18/20\n",
      "62930/62930 [==============================] - 988s 16ms/step - loss: 0.5550 - acc: 0.9780 - dice_coef: 0.7140 - soft_dice_coef: 0.5989 - val_loss: 0.7024 - val_acc: 0.9786 - val_dice_coef: 0.7275 - val_soft_dice_coef: 0.7022\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.69728\n",
      "Epoch 19/20\n",
      "62930/62930 [==============================] - 989s 16ms/step - loss: 0.5894 - acc: 0.9771 - dice_coef: 0.7138 - soft_dice_coef: 0.6713 - val_loss: 0.8022 - val_acc: 0.9730 - val_dice_coef: 0.7009 - val_soft_dice_coef: 0.6526\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.69728\n",
      "Epoch 20/20\n",
      "62930/62930 [==============================] - 988s 16ms/step - loss: 0.5173 - acc: 0.9795 - dice_coef: 0.7285 - soft_dice_coef: 0.6442 - val_loss: 0.6894 - val_acc: 0.9781 - val_dice_coef: 0.7379 - val_soft_dice_coef: 0.6471\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69728 to 0.68940, saving model to ./output/unet_model_for_decathlon.hdf5\n",
      "------------------------------\n",
      "Loading the best trained model ...\n",
      "------------------------------\n",
      "Evaluating model on test dataset. Please wait...\n",
      "7130/7130 [==============================] - 56s 8ms/step\n",
      "7130 images in 56.25 seconds => 126.761 images per second inference\n",
      "Test dataset loss = 0.6996\n",
      "Test dataset acc = 0.9787\n",
      "Test dataset dice_coef = 0.7360\n",
      "Test dataset soft_dice_coef = 0.6313\n",
      "------------------------------\n",
      "Freezing model and saved to a TensorFlow protobuf ...\n",
      "------------------------------\n",
      "Frozen TensorFlow model written to: ./frozen_model/unet_model_for_decathlon.pb\n",
      "Convert this to OpenVINO by running:\n",
      "\n",
      "source /opt/intel/openvino/bin/setupvars.sh\n",
      "python $INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \\\n",
      "       --input_model ./frozen_model/unet_model_for_decathlon.pb \\\n",
      "       --input_shape [1,144,144,1] \\\n",
      "       --output_dir openvino_models/FP32/ \\\n",
      "       --data_type FP32\n",
      "\n",
      "\n",
      "Total time elapsed for program = 5:30:47.735288 seconds\n",
      "Stopped script on 2020-01-22 03:04:39.786304\n",
      " \n",
      "****************************************\n",
      "Step 3 of 4: Run sample inference script\n",
      "****************************************\n",
      "Using TensorFlow backend.\n",
      "plot_inference_examples.py:35: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"plot_inference_examples.py\", line 34, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(\"Agg\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format = channels_last\n",
      "Dice 0.7512, Soft Dice 0.7507, Saved png file to: inference_examples/pred_50.png\n",
      "Dice 0.8048, Soft Dice 0.8052, Saved png file to: inference_examples/pred_61.png\n",
      "Dice 0.7599, Soft Dice 0.7599, Saved png file to: inference_examples/pred_102.png\n",
      "Dice 0.6246, Soft Dice 0.6239, Saved png file to: inference_examples/pred_210.png\n",
      "Dice 0.8414, Soft Dice 0.8416, Saved png file to: inference_examples/pred_371.png\n",
      "Dice 0.3861, Soft Dice 0.3853, Saved png file to: inference_examples/pred_400.png\n",
      "Dice 1.0000, Soft Dice 0.6294, Saved png file to: inference_examples/pred_1093.png\n",
      "Dice 0.0000, Soft Dice 0.0000, Saved png file to: inference_examples/pred_2222.png\n",
      "Dice 1.0000, Soft Dice 0.6161, Saved png file to: inference_examples/pred_3540.png\n",
      "Dice 1.0000, Soft Dice 0.9964, Saved png file to: inference_examples/pred_4485.png\n",
      "Dice 1.0000, Soft Dice 0.9848, Saved png file to: inference_examples/pred_5566.png\n",
      "Dice 0.3691, Soft Dice 0.3693, Saved png file to: inference_examples/pred_5675.png\n",
      "Dice 0.8429, Soft Dice 0.8427, Saved png file to: inference_examples/pred_6433.png\n",
      " \n",
      "********************************************************\n",
      "Step 4 of 4: Converting the TensorFlow model to OpenVINO\n",
      "********************************************************\n",
      "If you have OpenVINO installed, then you can run the following command\n",
      "to create the OpenVINO model.\n",
      "\n",
      "source /opt/intel/openvino/bin/setupvars.sh\n",
      "python /deployment_tools/model_optimizer/mo_tf.py \\\n",
      "   --input_model ./frozen_model/unet_model_for_decathlon.pb \\\n",
      "   --input_shape [1,144,144,4] \\\n",
      "   --output_dir openvino_models/FP32/ \\\n",
      "   --data_type FP32  --model_name saved_model\n",
      " \n"
     ]
    }
   ],
   "source": [
    "%cd unet/2D\n",
    "!bash run_brats_model.sh $DECATHLON_ROOT_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
