{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D U-Net Inference\n",
    "\n",
    "This notebook shows how to perform inference on the trained model using both the Keras/TensorFlow model and the OpenVINO model. It also compares the outputs to show that OpenVINO is faster on the same hardware than Keras/TensorFlow and produces the same predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always run the OpenVINO setup variable script before using it for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you haven't converted the model already, then use the OpenVINO model optimizer to convert from TensorFlow to OpenVINO.\n",
    "\n",
    "The file `tf_protobuf/3d_unet_decathlon.pb` should be automatically created at the end of `train.py` by using the best trained Keras HDF5 model file. (From TensorFlow 2.0 and onward, the saved files should all be TensorFlow protobuf (.pb))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python $INTEL_OPENVINO_DIR/deployment_tools/model_optimizer/mo_tf.py \\\n",
    "        --input_model tf_protobuf/3d_unet_decathlon.pb  \\\n",
    "        --input_shape [1,1,144,144,144]  \\\n",
    "        --output_dir openvino_models/FP32/ \\\n",
    "        --data_type FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Get rid of the AVX, SSE warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    number_iter = 5\n",
    "    device = \"CPU\"\n",
    "    stats = False\n",
    "    plot=False\n",
    "    csv_file = \"test.csv\"\n",
    "    openvino_model = \"./openvino_models/FP32/3d_unet_decathlon.xml\"\n",
    "    keras_model = \"./saved_model/3d_unet_decathlon.hdf5\"\n",
    "    cpu_extension=\"\"\n",
    "    plugin_dir=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, truth):\n",
    "    \"\"\"\n",
    "    Sorensen Dice score\n",
    "    Measure of the overlap between the prediction and ground truth masks\n",
    "    \"\"\"\n",
    "    numerator = np.sum(np.round(pred) * truth) * 2.0\n",
    "    denominator = np.sum(np.round(pred)) + np.sum(truth)\n",
    "\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop image at center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, msk, crop_dim, n_channels, n_out_channels):\n",
    "    \"\"\"\n",
    "    Crop the image and mask\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_dimensions = len(crop_dim)\n",
    "\n",
    "    slices = []\n",
    "\n",
    "    for idx in range(number_of_dimensions):  # Go through each dimension\n",
    "\n",
    "        cropLen = crop_dim[idx]\n",
    "        imgLen = img.shape[idx]\n",
    "\n",
    "        start = (imgLen-cropLen)//2\n",
    "\n",
    "        slices.append(slice(start, start+cropLen))\n",
    "\n",
    "    # No slicing along channels\n",
    "    slices_img = slices.copy()\n",
    "    slices_msk = slices.copy()\n",
    "\n",
    "    slices_img.append(slice(0, n_channels))\n",
    "    slices_msk.append(slice(0, n_out_channels))\n",
    "\n",
    "    return img[tuple(slices_img)], msk[tuple(slices_msk)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_normalize_img(img):\n",
    "    \"\"\"\n",
    "    Normalize the image so that the mean value for each image\n",
    "    is 0 and the standard deviation is 1.\n",
    "    \"\"\"\n",
    "    for channel in range(img.shape[-1]):\n",
    "\n",
    "        img_temp = img[..., channel]\n",
    "        img_temp = (img_temp - np.mean(img_temp)) / np.std(img_temp)\n",
    "\n",
    "        img[..., channel] = img_temp\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Nifti files\n",
    "\n",
    "The critical point is that OpenVINO expects the tensor to be in a different order than TensorFlow (channels first versus channels last).  Notice that we simply need to transpose the dimensions after loading to get it in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(imgFile, mskFile, crop_dim, n_channels, n_out_channels, openVINO_order=True):\n",
    "    \"\"\"\n",
    "    Modify this to load your data and labels\n",
    "    \"\"\"\n",
    "\n",
    "    imgs = np.empty((len(imgFile),*crop_dim,n_channels))\n",
    "    msks = np.empty((len(mskFile),*crop_dim,n_out_channels))\n",
    "    fileIDs = []\n",
    "\n",
    "    for idx in range(len(imgFile)):\n",
    "\n",
    "        img_temp = np.array(nib.load(imgFile[idx]).dataobj)\n",
    "        msk = np.array(nib.load(mskFile[idx]).dataobj)\n",
    "\n",
    "        if n_channels == 1:\n",
    "            img = img_temp[:, :, :, [0]]  # FLAIR channel\n",
    "        else:\n",
    "            img = img_temp\n",
    "\n",
    "        # Add channels to mask\n",
    "        msk[msk > 0] = 1.0\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "\n",
    "\n",
    "        # Crop the image to the input size\n",
    "        img, msk = crop_img(img, msk, crop_dim, n_channels, n_out_channels)\n",
    "\n",
    "        # z-normalize the pixel values\n",
    "        img = z_normalize_img(img)\n",
    "\n",
    "        fileIDs.append(os.path.basename(imgFile[idx]))\n",
    "\n",
    "        imgs[idx] = img\n",
    "        msks[idx] = msk\n",
    "\n",
    "    if openVINO_order:\n",
    "        imgs = imgs.transpose((0, 4, 1, 2, 3))\n",
    "        msks = msks.transpose((0, 4, 1, 2, 3))\n",
    "\n",
    "    return imgs, msks, fileIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the OpenVINO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_xml, fp16=False):\n",
    "    \"\"\"\n",
    "    Load the OpenVINO model.\n",
    "    \"\"\"\n",
    "    log.info(\"Loading U-Net model to the plugin\")\n",
    "\n",
    "    model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "    return model_xml, model_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the OpenVINO statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(exec_net, input_data, n_channels, batch_size, input_blob, out_blob, args):\n",
    "    \"\"\"\n",
    "    Prints layer by layer inference times.\n",
    "    Good for profiling which ops are most costly in your model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start sync inference\n",
    "    log.info(\"Starting inference ({} iterations)\".format(args.number_iter))\n",
    "    log.info(\"Number of input channels = {}\".format(n_channels))\n",
    "    log.info(\"Input data shape = {}\".format(input_data.shape))\n",
    "    infer_time = []\n",
    "\n",
    "    for i in range(args.number_iter):\n",
    "        t0 = time()\n",
    "        res = exec_net.infer(\n",
    "            inputs={input_blob: input_data[0:batch_size, :n_channels]})\n",
    "        infer_time.append((time() - t0) * 1000)\n",
    "\n",
    "    average_inference = np.average(np.asarray(infer_time))\n",
    "    log.info(\"Average running time of one batch: {:.5f} ms\".format(\n",
    "        average_inference))\n",
    "    log.info(\"Images per second = {:.3f}\".format(\n",
    "        batch_size * 1000.0 / average_inference))\n",
    "\n",
    "    perf_counts = exec_net.requests[0].get_perf_counts()\n",
    "    log.info(\"Performance counters:\")\n",
    "    log.info(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format(\"name\",\n",
    "                                                         \"layer_type\",\n",
    "                                                         \"exec_type\",\n",
    "                                                         \"status\",\n",
    "                                                         \"real_time, us\"))\n",
    "    for layer, stats in perf_counts.items():\n",
    "        log.info(\"{:<70} {:<15} {:<15} {:<15} {:<10}\".format(layer,\n",
    "                                                             stats[\"layer_type\"],\n",
    "                                                             stats[\"exec_type\"],\n",
    "                                                             stats[\"status\"],\n",
    "                                                             stats[\"real_time\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(filename):\n",
    "    \"\"\"\n",
    "    Read the CSV file with the image and mask filenames\n",
    "    \"\"\"\n",
    "    imgFiles = []\n",
    "    mskFiles = []\n",
    "    with open(filename, \"rt\") as f:\n",
    "        data = csv.reader(f)\n",
    "        for row in data:\n",
    "            if len(row) > 0:\n",
    "                imgFiles.append(row[0])\n",
    "                mskFiles.append(row[1])\n",
    "\n",
    "    return imgFiles, mskFiles, len(imgFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\",\n",
    "                level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "log.info(args)\n",
    "\n",
    "log.info(\"Loading test data from file: {}\".format(args.csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "if args.cpu_extension and \"CPU\" in args.device:\n",
    "    ie.add_extension(args.cpu_extension, \"CPU\")\n",
    "\n",
    "# Read IR\n",
    "# If using MYRIAD then we need to load FP16 model version\n",
    "model_xml, model_bin = load_model(args.openvino_model, args.device == \"MYRIAD\")\n",
    "log.info(\"Loading network files:\\n\\t{}\\n\\t{}\".format(model_xml, model_bin))\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "if \"CPU\" in args.device:\n",
    "    supported_layers = ie.query_network(net, \"CPU\")\n",
    "    not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "    if len(not_supported_layers) != 0:\n",
    "        log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                  format(args.device, ', '.join(not_supported_layers)))\n",
    "        log.error(\"Please try to specify cpu extensions library path in sample's command line parameters using -l \"\n",
    "                  \"or --cpu_extension command line argument\")\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ask OpenVINO for input and output tensor names and sizes\n",
    "\"\"\"\n",
    "input_blob = next(iter(net.inputs))  # Name of the input layer\n",
    "out_blob = next(iter(net.outputs))   # Name of the output layer\n",
    "\n",
    "# Load data\n",
    "batch_size, n_channels, height, width, depth = net.inputs[input_blob].shape\n",
    "batch_size, n_out_channels, height_out, width_out, depth_out = net.outputs[out_blob].shape\n",
    "crop_dim = [height, width, depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the CSV file with the filenames of the images and masks\n",
    "\"\"\"\n",
    "imgFiles, mskFiles, num_imgs = read_csv_file(args.csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the data for OpenVINO\n",
    "\"\"\"\n",
    "input_data, label_data_ov, img_indicies = load_data(imgFiles, mskFiles,\n",
    "            crop_dim, n_channels, n_out_channels, openVINO_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable input and batch size\n",
    "For certain networks, the input shape and batch size can be changed during model load. This can be useful for fully convlutional networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the OpenVINO network to accept the different image input shape\n",
    "# NOTE: This only works for some models (e.g. fully convolutional)\n",
    "batch_size = 1\n",
    "n_channels = input_data.shape[1]\n",
    "height = input_data.shape[2]\n",
    "width = input_data.shape[3]\n",
    "depth = input_data.shape[4]\n",
    "\n",
    "net.reshape({input_blob:(batch_size,n_channels,height,width,depth)})\n",
    "batch_size, n_channels, height, width, depth = net.inputs[input_blob].shape\n",
    "batch_size, n_out_channels, height_out, width_out, depth_out = net.outputs[out_blob].shape\n",
    "\n",
    "log.info(\"The network inputs are:\")\n",
    "for idx, input_layer in enumerate(net.inputs.keys()):\n",
    "    log.info(\"{}: {}, shape = {} [N,C,H,W,D]\".format(idx,input_layer,net.inputs[input_layer].shape))\n",
    "\n",
    "log.info(\"The network outputs are:\")\n",
    "for idx, output_layer in enumerate(net.outputs.keys()):\n",
    "    log.info(\"{}: {}, shape = {} [N,C,H,W,D]\".format(idx,output_layer,net.outputs[output_layer].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model to the plugin\n",
    "log.info(\"Loading model to the plugin\")\n",
    "exec_net = ie.load_network(network=net, device_name=args.device)\n",
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.stats:\n",
    "    # Print the latency and throughput for inference\n",
    "    print_stats(exec_net, input_data, n_channels,\n",
    "                batch_size, input_blob, out_blob, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OpenVINO inference code\n",
    "input_blob is the name (string) of the input tensor in the graph\n",
    "out_blob is the name (string) of the output tensor in the graph\n",
    "Essentially, this looks exactly like a feed_dict for TensorFlow inference\n",
    "\"\"\"\n",
    "# Go through the sample validation dataset to plot predictions\n",
    "predictions_ov = np.zeros((num_imgs, n_out_channels,\n",
    "                        depth_out, height_out, width_out))\n",
    "\n",
    "log.info(\"Starting OpenVINO inference\")\n",
    "ov_times = []\n",
    "for idx in tqdm(range(0, num_imgs)):\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    res = exec_net.infer(inputs={input_blob: input_data[[idx],:n_channels]})\n",
    "\n",
    "    ov_times.append(time() - start_time)\n",
    "\n",
    "    predictions_ov[idx, ] = res[out_blob]\n",
    "\n",
    "    #print(\"{}, {}\".format(imgFiles[idx], dice_score(res[out_blob],label_data_ov[idx])))\n",
    "\n",
    "\n",
    "log.info(\"Finished OpenVINO inference\")\n",
    "\n",
    "del exec_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the data for Keras\n",
    "\"\"\"\n",
    "input_data, label_data_keras, img_indicies = load_data(imgFiles, mskFiles,\n",
    "                    crop_dim, n_channels, n_out_channels,\n",
    "                    openVINO_order=False)\n",
    "\n",
    "# Load OpenVINO model for inference\n",
    "model = K.models.load_model(args.keras_model, compile=False)\n",
    "\n",
    "# Inference only Keras\n",
    "K.backend._LEARNING_PHASE = tf.constant(0)\n",
    "K.backend.set_learning_phase(False)\n",
    "K.backend.set_learning_phase(0)\n",
    "K.backend.set_image_data_format(\"channels_last\")\n",
    "\n",
    "predictions_keras = np.zeros((num_imgs,\n",
    "                        height_out, width_out, depth_out, n_out_channels))\n",
    "\n",
    "log.info(\"Starting Keras inference\")\n",
    "keras_times = []\n",
    "for idx in tqdm(range(num_imgs)):\n",
    "\n",
    "    start_time = time()\n",
    "    res = model.predict(input_data[[idx],...,:n_channels])\n",
    "\n",
    "    keras_times.append(time() - start_time)\n",
    "\n",
    "    #print(\"{}, {}\".format(imgFiles[idx], dice_score(res,label_data_keras[idx])))\n",
    "\n",
    "    predictions_keras[idx] = res\n",
    "\n",
    "log.info(\"Finished Keras inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"predictions_openvino\"\n",
    "try:\n",
    "    os.stat(save_directory)\n",
    "except:\n",
    "    os.mkdir(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(idx):\n",
    "    \"\"\"\n",
    "    Evaluate model with Dice metric\n",
    "    \"\"\"\n",
    "    out_channel = 0\n",
    "    slice_no = 102\n",
    "    \n",
    "    img = input_data[[idx],...,:n_channels]\n",
    "    ground_truth = label_data_keras[idx, :, :, :, out_channel]\n",
    "\n",
    "    # Transpose the OpenVINO prediction back to NCHWD (to be consistent with Keras)\n",
    "    pred_ov = np.transpose(predictions_ov, [0,2,3,4,1])[idx, :, :, :, out_channel]\n",
    "    pred_keras = predictions_keras[idx, :, :, :, out_channel]\n",
    "\n",
    "    dice_ov = dice_score(pred_ov, ground_truth)\n",
    "    dice_keras = dice_score(pred_keras, ground_truth)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(img[0,:,:,slice_no,0], cmap=\"bone\")\n",
    "    plt.title(\"MRI\")\n",
    "    \n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(ground_truth[:,:,slice_no])\n",
    "    plt.title(\"Ground truth\")\n",
    "    \n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(pred_keras[:,:,slice_no])\n",
    "    plt.title(\"Keras\\nDice {:.6f}\".format(dice_keras))\n",
    "    \n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(pred_ov[:,:,slice_no])\n",
    "    plt.title(\"OpenVINO\\nDice {:.6f}\".format(dice_ov))\n",
    "    \n",
    "    log.info(\"Maximum Absolute Pixel Difference in Predictions is {:.6f}\".format(np.max(np.abs(pred_ov[:,:,slice_no] - pred_keras[:,:,slice_no]))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some sample predictions\n",
    "\n",
    "Here we show the MRI input, the ground truth mask, the Keras/TF model prediction, and the OpenVINO model prediction. We also calculate the maximum absolute pixel difference which is usually < 1e-5 (on the order of floating point precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_predictions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Average inference time: \\n\"\n",
    "         \"OpenVINO = {} seconds (s.d. {})\\n\"\n",
    "         \"Keras/TF = {} seconds (s.d. {})\\n\".format(np.mean(ov_times),\n",
    "         np.std(ov_times),\n",
    "         np.mean(keras_times),\n",
    "         np.std(keras_times)))\n",
    "log.info(\"Raw OpenVINO inference times = {} seconds\".format(ov_times))\n",
    "log.info(\"Raw Keras inference times = {} seconds\".format(keras_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
